{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shikhar00778/toxic-comment-classification/blob/master/Toxic_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T23:13:49.863257Z",
     "start_time": "2019-06-07T23:13:04.610838Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1040
    },
    "colab_type": "code",
    "id": "FJky7eq3pyYt",
    "outputId": "209aed97-e298-4f1c-d70d-87a15fa50b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/kaushaltrivedi/fast-bert.git\n",
      "  Cloning https://github.com/kaushaltrivedi/fast-bert.git to /tmp/pip-hozlau1v-build\n",
      "Requirement already satisfied: pytorch-pretrained-bert>=0.6.2 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fast-bert==0.1.2)\n",
      "Requirement already satisfied: fastai in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fast-bert==0.1.2)\n",
      "Requirement already satisfied: regex in /home/windywinter/anaconda3/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: requests in /home/windywinter/anaconda3/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: boto3 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: numpy in /home/windywinter/anaconda3/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: tqdm in /home/windywinter/anaconda3/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: bottleneck in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: fastprogress>=0.1.19 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: matplotlib in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: numexpr in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: pandas in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: packaging in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: Pillow in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: pyyaml in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: scipy in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: typing in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: spacy>=2.0.18 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: torchvision in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: dataclasses in /home/windywinter/anaconda3/lib/python3.6/site-packages (from fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.134 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from matplotlib->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from matplotlib->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from matplotlib->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: pytz in /home/windywinter/anaconda3/lib/python3.6/site-packages (from matplotlib->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: six>=1.10 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from matplotlib->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from matplotlib->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: ujson>=1.35 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.134->boto3->pytorch-pretrained-bert>=0.6.2->fast-bert==0.1.2)\n",
      "Requirement already satisfied: setuptools in /home/windywinter/anaconda3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /home/windywinter/anaconda3/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai->fast-bert==0.1.2)\n",
      "Installing collected packages: fast-bert\n",
      "  Running setup.py install for fast-bert ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed fast-bert-0.1.2\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/kaushaltrivedi/fast-bert.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T23:09:11.038702Z",
     "start_time": "2019-06-07T23:09:10.835314Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mufR18pJV1sg",
    "outputId": "d95f076c-65fb-443a-ca3a-5ef809780c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/windywinter/anaconda/python3.6/dist-packages/fast_bert/metrics.py\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/windywinter/anaconda/python3.6/dist-packages/fast_bert/metrics.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-35c434c3f387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home/windywinter/anaconda/python3.6/dist-packages/fast_bert/metrics.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'import numpy as np\\nfrom torch import Tensor\\nfrom sklearn.metrics import roc_curve, auc, hamming_loss, accuracy_score\\nimport pdb\\n\\n# def accuracy(out, labels):\\n#     outputs = np.argmax(out, axis=1)\\n#     return np.sum(outputs == labels)\\n\\ndef accuracy(y_pred:Tensor, y_true:Tensor):\\n\\n    outputs = np.argmax(y_pred, axis=1)\\n    return np.mean(outputs.numpy() == y_true.detach().cpu().numpy())\\n\\ndef accuracy_multilabel(y_pred:Tensor, y_true:Tensor, sigmoid:bool=True):\\n    if sigmoid: y_pred = y_pred.sigmoid()\\n    outputs = np.argmax(y_pred, axis=1)\\n    real_vals = np.argmax(y_true, axis=1)\\n    return np.mean(outputs.numpy() == real_vals.numpy())\\n\\ndef accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\\n    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\\n    if sigmoid: y_pred = y_pred.sigmoid()\\n    return ((y_pred>thresh)==y_true.byte()).float().mean().item()\\n#     return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\\n\\n\\ndef fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.3, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\\n    \"Computes the f_beta between `preds` and `targets`\"\\n    beta2 = beta ** 2\\n    if sigmoid: y_pred = y_pred.sigmoid()\\n    y_pred = (y_pred>thresh).float()\\n    y_true = y_true.float()\\n    TP = (y_pred*y_true).sum(dim=1)\\n    prec = TP/(y_pred.sum(dim=1)+eps)\\n    rec = TP/(y_true.sum(dim=1)+eps)\\n    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\\n    return res.mean().item()\\n\\ndef roc_auc(y_pred: Tensor, y_true: Tensor):\\n    # ROC-AUC calcualation\\n    # Compute ROC curve and ROC area for each class\\n    fpr = dict()\\n    tpr = dict()\\n    roc_auc = dict()\\n    \\n    y_true = y_true.detach().cpu().numpy()\\n    y_pred = y_pred.detach().cpu().numpy()\\n        \\n    # Compute micro-average ROC curve and ROC area\\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\\n    \\n    return roc_auc[\"micro\"]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2101\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2103\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2104\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-106>\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/windywinter/anaconda/python3.6/dist-packages/fast_bert/metrics.py'"
     ]
    }
   ],
   "source": [
    "%%writefile /home/windywinter/anaconda/python3.6/dist-packages/fast_bert/metrics.py\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from sklearn.metrics import roc_curve, auc, hamming_loss, accuracy_score\n",
    "import pdb\n",
    "\n",
    "# def accuracy(out, labels):\n",
    "#     outputs = np.argmax(out, axis=1)\n",
    "#     return np.sum(outputs == labels)\n",
    "\n",
    "def accuracy(y_pred:Tensor, y_true:Tensor):\n",
    "\n",
    "    outputs = np.argmax(y_pred, axis=1)\n",
    "    return np.mean(outputs.numpy() == y_true.detach().cpu().numpy())\n",
    "\n",
    "def accuracy_multilabel(y_pred:Tensor, y_true:Tensor, sigmoid:bool=True):\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    outputs = np.argmax(y_pred, axis=1)\n",
    "    real_vals = np.argmax(y_true, axis=1)\n",
    "    return np.mean(outputs.numpy() == real_vals.numpy())\n",
    "\n",
    "def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
    "#     return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
    "\n",
    "\n",
    "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.3, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "    beta2 = beta ** 2\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = (y_pred>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=1)\n",
    "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=1)+eps)\n",
    "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
    "    return res.mean().item()\n",
    "\n",
    "def roc_auc(y_pred: Tensor, y_true: Tensor):\n",
    "    # ROC-AUC calcualation\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    y_true = y_true.detach().cpu().numpy()\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "        \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    return roc_auc[\"micro\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T23:14:00.617966Z",
     "start_time": "2019-06-07T23:13:57.277494Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JjGiE2cVR2XG",
    "outputId": "6375a4b1-d0f0-41ed-8468-c12a45a462f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/windywinter/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.preprocessing import text,sequence\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "from fastai.train import Learner\n",
    "from fastai.train import DataBunch\n",
    "from fastai.callbacks import *\n",
    "from fastai.metrics import *\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pytorch_pretrained_bert\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "from fast_bert.data import BertDataBunch\n",
    "from fast_bert.learner import BertLearner\n",
    "from fast_bert.metrics import accuracy , accuracy_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T23:14:34.559558Z",
     "start_time": "2019-06-07T23:14:34.550813Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nqm3k_2aW_IG"
   },
   "outputs": [],
   "source": [
    "\n",
    "args = {\n",
    "    \"max_seq_length\": 220,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"num_train_epochs\": 12.0,\n",
    "    \"warmup_proportion\": 0.002,\n",
    "    \"local_rank\": -1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"fp16\": True,\n",
    "    \"loss_scale\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T23:14:37.668692Z",
     "start_time": "2019-06-07T23:14:37.662892Z"
    },
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "u8H9kp1VtEr8"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4287
    },
    "colab_type": "code",
    "id": "nM5cBSwgKalm",
    "outputId": "55a58f74-15b2-4855-9589-9660f0ec960c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 73, done.\u001b[K\n",
      "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
      "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
      "remote: Total 4467 (delta 38), reused 40 (delta 20), pack-reused 4394\u001b[K\n",
      "Receiving objects: 100% (4467/4467), 8.67 MiB | 14.82 MiB/s, done.\n",
      "Resolving deltas: 100% (2866/2866), done.\n",
      "/content/apex\n",
      "torch.__version__  =  1.1.0\n",
      "\n",
      "Compiling cuda extensions with\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n",
      "from /usr/local/cuda/bin\n",
      "\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating apex.egg-info\n",
      "writing apex.egg-info/PKG-INFO\n",
      "writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "writing top-level names to apex.egg-info/top_level.txt\n",
      "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib.linux-x86_64-3.6\n",
      "creating build/lib.linux-x86_64-3.6/apex\n",
      "copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
      "creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "creating build/lib.linux-x86_64-3.6/apex/RNN\n",
      "copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "creating build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "creating build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "creating build/lib.linux-x86_64-3.6/apex/normalization\n",
      "copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "running build_ext\n",
      "building 'apex_C' extension\n",
      "creating build/temp.linux-x86_64-3.6\n",
      "creating build/temp.linux-x86_64-3.6/csrc\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'amp_C' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'fused_adam_cuda' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'syncbn' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'fused_layer_norm_cuda' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/apex\n",
      "creating build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "copying build/lib.linux-x86_64-3.6/apex/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "creating build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "creating build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "creating build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "creating build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n",
      "creating build/bdist.linux-x86_64/egg/apex/normalization\n",
      "copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
      "copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
      "creating build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
      "copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
      "copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
      "creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "creating build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
      "creating stub loader for apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "creating stub loader for amp_C.cpython-36m-x86_64-linux-gnu.so\n",
      "creating stub loader for fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "creating stub loader for syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "creating stub loader for fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex_C.py to apex_C.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/amp_C.py to amp_C.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fused_adam_cuda.py to fused_adam_cuda.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/syncbn.py to syncbn.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fused_layer_norm_cuda.py to fused_layer_norm_cuda.cpython-36.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.amp_C.cpython-36: module references __file__\n",
      "__pycache__.apex_C.cpython-36: module references __file__\n",
      "__pycache__.fused_adam_cuda.cpython-36: module references __file__\n",
      "__pycache__.fused_layer_norm_cuda.cpython-36: module references __file__\n",
      "__pycache__.syncbn.cpython-36: module references __file__\n",
      "creating dist\n",
      "creating 'dist/apex-0.1-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing apex-0.1-py3.6-linux-x86_64.egg\n",
      "creating /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6-linux-x86_64.egg\n",
      "Extracting apex-0.1-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
      "Adding apex 0.1 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6-linux-x86_64.egg\n",
      "Processing dependencies for apex==0.1\n",
      "Finished processing dependencies for apex==0.1\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/apex.git\n",
    "%cd apex\n",
    "!python setup.py install --cuda_ext --cpp_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AlMo6sIeJurL",
    "outputId": "c4392e3d-f5dc-4b52-86ab-fbbc95cf32bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DWg96ebMZL7n",
    "outputId": "2ad044bc-9efc-48d7-a138-3ed656916d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apex  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "b7fOTHTd529a",
    "outputId": "2811e495-a22f-41fd-ee54-24d9fd234355"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/26/2019 17:49:21 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yj-y2QO06TxD"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "# check if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    multi_gpu = True\n",
    "else:\n",
    "    multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "PEbps9qcGyDw",
    "outputId": "b269f3ff-dfc7-49d2-ad54-b3f3ed6a52b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-26 17:21:23--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/8076/all.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559149508&Signature=hZ8h%2BCpqFHDys56iBcLfz6SKnx4twthzyCngCYsMa4WAkEhhoASfcs9l2TcmAxLSMBkdPyaWZapiY5KwRXRcU6jan%2BphNLOGCRMzQ2FHqT8ia%2BFHfTNL1f57V4JIGfl01%2FeagyXlphuXi0U62O8UPuwoN6nplXKDBX9qBwoT3B%2Fd1YFUqr27ej7TegcMQ55S2xNlXMgddzCiBIkVOfsqEkLx2j2%2FaEL1RqLHfb0Sy4X%2FjrPaATbD2%2FWltXX0k20vzt%2BZDLfG%2FHjRAZCd7C0KU3moa8NPenqqbTVsTQj%2FbFBSrhlgJfrkGK1Gth%2BW8VdG1uNjKOd6ATePO%2BGnDX7QjA%3D%3D&response-content-disposition=attachment%3B+filename%3Djigsaw-toxic-comment-classification-challenge.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c07::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 55956017 (53M) [application/zip]\n",
      "Saving to: jigsaw-toxic-comment-classification-challenge.zip\n",
      "\n",
      "jigsaw-toxic-commen 100%[===================>]  53.36M  61.7MB/s    in 0.9s    \n",
      "\n",
      "2019-05-26 17:21:24 (61.7 MB/s) - jigsaw-toxic-comment-classification-challenge.zip saved [55956017/55956017]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/8076/all.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559149508&Signature=hZ8h%2BCpqFHDys56iBcLfz6SKnx4twthzyCngCYsMa4WAkEhhoASfcs9l2TcmAxLSMBkdPyaWZapiY5KwRXRcU6jan%2BphNLOGCRMzQ2FHqT8ia%2BFHfTNL1f57V4JIGfl01%2FeagyXlphuXi0U62O8UPuwoN6nplXKDBX9qBwoT3B%2Fd1YFUqr27ej7TegcMQ55S2xNlXMgddzCiBIkVOfsqEkLx2j2%2FaEL1RqLHfb0Sy4X%2FjrPaATbD2%2FWltXX0k20vzt%2BZDLfG%2FHjRAZCd7C0KU3moa8NPenqqbTVsTQj%2FbFBSrhlgJfrkGK1Gth%2BW8VdG1uNjKOd6ATePO%2BGnDX7QjA%3D%3D&response-content-disposition=attachment%3B+filename%3Djigsaw-toxic-comment-classification-challenge.zip\" -O \"jigsaw-toxic-comment-classification-challenge.zip\" -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "EsT9SgJvG0bO",
    "outputId": "aeac5ac4-08d0-443c-e2e4-04fa52209be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  jigsaw-toxic-comment-classification-challenge.zip\n",
      "  inflating: test_labels.csv         \n",
      "  inflating: sample_submission.csv   \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "!unzip jigsaw-toxic-comment-classification-challenge.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "yISr74VdG3eB",
    "outputId": "c71ae890-4e57-42c1-9626-c0fe5d78a000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apex\t\t\t\t\t\t   test.csv\n",
      "jigsaw-toxic-comment-classification-challenge.zip  test_labels.csv\n",
      "labels.csv\t\t\t\t\t   train.csv\n",
      "sample_data\t\t\t\t\t   valid.csv\n",
      "sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oPWqgv5t6Xjg"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aYOKGOgbHCFy"
   },
   "outputs": [],
   "source": [
    "df_valid = df[120000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CLjPIOVhHZUW"
   },
   "outputs": [],
   "source": [
    "df_train = df[:120000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "mc1c5zW1_h7G",
    "outputId": "3462e044-9fa9-46a9-eb30-8108afdd5d4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  ... identity_hate\n",
       "0  0000997932d777bf  ...             0\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tvGzRrBs6z1A"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.rename(index=str, columns={\"comment_text\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mVFjtLZdByNO"
   },
   "outputs": [],
   "source": [
    "df_valid = df_valid.rename(index=str, columns={\"comment_text\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-_QrMkwLHkrA"
   },
   "outputs": [],
   "source": [
    "!rm -r train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Lk1hXWrb7B-q"
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tv3FbYpFB72a"
   },
   "outputs": [],
   "source": [
    "df_valid.to_csv('valid.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pBys0Jq9H23S"
   },
   "outputs": [],
   "source": [
    "l = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']\n",
    "df_label = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "t5_92oY_IC3t"
   },
   "outputs": [],
   "source": [
    "df_label.to_csv('labels.csv' , index = False , header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mso4XYs_5Na4"
   },
   "outputs": [],
   "source": [
    "databunch = BertDataBunch('/content', '/content', tokenizer, \n",
    "                          train_file='train.csv', val_file='valid.csv',label_file='labels.csv',label_col=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate'],\n",
    "                          bs=args['train_batch_size'], maxlen=args['max_seq_length'], \n",
    "                          multi_gpu=multi_gpu, multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p7PGZAw0tK0L",
    "outputId": "510b747f-8ba6-444c-a53c-8a175f0e7d66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger __main__ (INFO)>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "u0axY-J86DlV",
    "outputId": "535b425a-2be2-47bb-ac15-dbb59b40bfe9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/26/2019 17:55:40 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "05/26/2019 17:55:40 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpnty1kvd1\n",
      "05/26/2019 17:55:44 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/26/2019 17:55:49 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "05/26/2019 17:55:49 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "metrics.append({'name': 'accuracy_multilabel', 'function': accuracy_multilabel})\n",
    "\n",
    "learner = BertLearner.from_pretrained_model(databunch, 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz', metrics, device, logger=logger, \n",
    "                                            finetuned_wgts_path=None, \n",
    "                                            is_fp16=args['fp16'], loss_scale=args['loss_scale'], \n",
    "                                            multi_gpu=multi_gpu,  multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "iLB2XXIgLBGK",
    "outputId": "a81caa08-3a3c-43b3-b07f-09c24a74871e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/26/2019 22:28:55 - INFO - __main__ -   Loss after epoch 0 - 0.032352679665883385\n",
      "05/26/2019 22:28:55 - INFO - __main__ -   Running evaluation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1237' class='' max='1237', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1237/1237 01:54<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/26/2019 22:30:50 - INFO - __main__ -   Eval results:\n",
      "05/26/2019 22:30:50 - INFO - __main__ -     eval_loss = 0.04371506529848905\n",
      "05/26/2019 22:30:50 - INFO - __main__ -     metrics = {'accuracy_multilabel': 0.9937833261732076}\n",
      "05/26/2019 22:30:50 - INFO - __main__ -   --------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "learner.fit(1, lr=args['learning_rate'], \n",
    "            schedule_type=\"warmup_cosine_hard_restarts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zAI1LYIhIY7I"
   },
   "outputs": [],
   "source": [
    " df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Kfwx3nskVUrW"
   },
   "outputs": [],
   "source": [
    "texts = list(df_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HDeRIoj6tp5Y"
   },
   "outputs": [],
   "source": [
    "predictions = learner.predict_batch([texts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "XjOLmJm1ZRdD",
    "outputId": "bc533d68-eefa-4985-f5d2-c43196d8a528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,\",\n",
       "  '== From RfC == \\n\\n The title is fine as it is, IMO.',\n",
       "  '\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland   /  \"'],\n",
       " [\"Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,\"],\n",
       " ['== From RfC == \\n\\n The title is fine as it is, IMO.',\n",
       "  '\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland   /  \"'])"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0:3] , texts[0:1] , texts[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u0XEOFyQYnPs",
    "outputId": "5869d248-d1d0-41dd-d7ee-16ac442ce9a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6962.0"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "osaLUBcBZK3d"
   },
   "outputs": [],
   "source": [
    "#predictions = learner.predict_batch([txt])\n",
    "  toxic.append(predictions[0][0][1])\n",
    "  obscene.append(predictions[0][1][1])\n",
    "  insult.append(predictions[0][2][1])\n",
    "  severe_toxic.append(predictions[0][3][1])\n",
    "  identity_hate.append(predictions[0][4][1])\n",
    "  threat.append(predictions[0][5][1])\n",
    "  \n",
    "  #print(toxic)\n",
    "  #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jk9S5EtpXeEr",
    "outputId": "f6601abb-1b5a-4e86-c76e-62f91b4f579e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6962/6962 [06:35<00:00, 14.68it/s]\n"
     ]
    }
   ],
   "source": [
    "toxic = []\n",
    "obscene = []\n",
    "insult = []\n",
    "severe_toxic = []\n",
    "identity_hate = []\n",
    "threat = []\n",
    "\n",
    "import tqdm\n",
    "for i in tqdm.tqdm(range(0,len(texts),22)):\n",
    "  txt = texts[i:i+22]\n",
    "  predictions = learner.predict_batch(txt)\n",
    "  \n",
    "  for j in range(22):\n",
    "    toxic.append(predictions[j][0][1])\n",
    "    obscene.append(predictions[j][1][1])\n",
    "    insult.append(predictions[j][2][1])\n",
    "    severe_toxic.append(predictions[j][3][1])\n",
    "    identity_hate.append(predictions[j][4][1])\n",
    "    threat.append(predictions[j][5][1])\n",
    "  \n",
    "  #print(toxic)\n",
    "  #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qoMrnytGbbGj",
    "outputId": "9dc535f6-4d4e-4db5-f854-51e1c45b006b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "x6d4DwsmBMUL"
   },
   "outputs": [],
   "source": [
    "df_test['toxic'] = toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PcvtIl0uPZ7F"
   },
   "outputs": [],
   "source": [
    "df_test['severe_toxic'] = severe_toxic\n",
    "df_test['obscene'] = obscene\n",
    "df_test['threat'] = threat\n",
    "df_test['insult'] = insult\n",
    "df_test['identity_hate'] = identity_hate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "JK462nIiRWbr"
   },
   "outputs": [],
   "source": [
    "!rm -r submission_bert.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "etCYgnmVb6sc"
   },
   "outputs": [],
   "source": [
    "df_test.to_csv('submission_bert.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "e2b-7OOYcjd6"
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['comment_text'] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pvR4S86ucX0m"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('submission_bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_WZNLaaihYon",
    "outputId": "7c2895b7-3544-46fb-d95b-76eec6b03422"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bJKmvqJWhcG0",
    "outputId": "93c3d01f-ec03-43e3-a1bb-0149a990bcc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9aToqNFroIh2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Toxic Bert.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
